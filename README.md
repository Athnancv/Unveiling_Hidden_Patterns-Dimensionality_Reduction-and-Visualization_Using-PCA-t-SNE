
# ğŸ§  Unveiling Hidden Patterns: Dimensionality Reduction and Visualization using PCA & t-SNE  

This repository presents a **hands-on exploration of dimensionality reduction** techniques using high-dimensional datasets. The focus is to demonstrate how **PCA (Principal Component Analysis)** and **t-SNE (t-Distributed Stochastic Neighbor Embedding)** help compress features and visualize complex data structures â€” all while maintaining strong model performance and interpretability.  

---

## ğŸ“Œ Overview  
ğŸ“‚ Loaded and preprocessed a high-dimensional dataset  
âš™ï¸ Standardized features using **StandardScaler** to normalize input data  
ğŸ“‰ Applied **PCA** to extract principal components capturing maximum variance  
ğŸŒ€ Used **t-SNE** to project the dataset into 2D and 3D visual spaces  
ğŸ¤– Compared baseline and reduced-dimension models using **Logistic Regression**  
ğŸ“Š Evaluated trade-offs between accuracy, variance retention, and visualization clarity  

---

## ğŸ’¡ Key Insights  
ğŸ”¹ **PCA** efficiently compresses features while preserving most of the dataâ€™s variance  
ğŸ”¹ **t-SNE** uncovers hidden structures and clusters that linear methods might miss  
ğŸ”¹ **Dimensionality reduction** improves visualization and reduces model complexity  
ğŸ”¹ Visual comparisons highlight the strengths of linear (PCA) vs. non-linear (t-SNE) approaches  

---

## ğŸ›  Tech Stack  
**Language:** Python  
**Libraries:** NumPy â€¢ Pandas â€¢ Scikit-learn â€¢ Matplotlib â€¢ Seaborn  

---

## ğŸ“Š Results  
ğŸ“ˆ Baseline Logistic Regression Accuracy: **98%**  
ğŸ“‰ Logistic Regression with PCA (Reduced Dimensions): **97%**  
ğŸŒ€ **t-SNE visualizations** reveal clear separations among classes with minor overlaps  
ğŸ¯ Dimensionality reduction achieved ~40% compression while retaining interpretability  

---

## ğŸš€ Conclusion  
This project showcases how **dimensionality reduction** techniques can make complex datasets more interpretable and visually meaningful. By combining **PCAâ€™s efficiency** with **t-SNEâ€™s expressiveness**, this notebook provides a strong foundation for exploratory data analysis, visualization, and feature optimization in real-world machine learning tasks.  
```
